{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import categorical_accuracy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, Dense, Dropout, ELU, Flatten, MaxPool2D\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.initializers import lecun_uniform\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "person_test = np.load(\"person_test.npy\")\n",
    "X_train_valid = X_train_valid[:, :22, :]\n",
    "X_test = X_test[:, :22, :]\n",
    "y_train_valid = to_categorical(y_train_valid - 769)\n",
    "y_test = to_categorical(y_test - 769)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (443, 22, 1000)\n",
      "y_test shape: (443, 4)\n",
      "person_train_valid shape: (2115, 1)\n",
      "X_train_valid shape: (2115, 22, 1000)\n",
      "y_train_valid shape: (2115, 4)\n",
      "person_test shape: (443, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"person_train_valid shape:\", person_train_valid.shape)\n",
    "print(\"X_train_valid shape:\", X_train_valid.shape)\n",
    "print(\"y_train_valid shape:\", y_train_valid.shape)\n",
    "print(\"person_test shape:\", person_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    # Convolutional layer with 32 filters, kernel size of 3x3, ReLU activation, and input shape defined\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(22, 1000, 1)),  # Adjust input_shape based on your data\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    # Another convolutional layer\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    # Flatten the output of the conv layers to feed into dense layers\n",
    "    Flatten(),\n",
    "    \n",
    "    # Dense layer with 128 units\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    # Output layer with softmax activation, number of units equals number of classes\n",
    "    Dense(4, activation='softmax')  # Use the actual number of classes in your task\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    # LSTM layer with 128 units. Adjust the input_shape to match your dataset.\n",
    "    # input_shape=(timesteps, features) where 'timesteps' is the length of the time sequence,\n",
    "    # and 'features' is the number of features at each timestep.\n",
    "    LSTM(128, input_shape=(22, 1000), activation='relu', return_sequences=True),  # Example input_shape\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    # Additional LSTM Layer, not returning sequences to flatten the output for the dense layer that follows\n",
    "    LSTM(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    # Dense layer for classification\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    # Output layer with softmax activation, number of units equals number of classes\n",
    "    Dense(4, activation='softmax')  # Replace 'number_of_classes' with the actual number\n",
    "])\n",
    "\n",
    "# Compilation of the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',  # or 'sparse_categorical_crossentropy' if your labels are integers\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',  # Use 'sparse_categorical_crossentropy' if your labels are integers\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 10, 128)           117248    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 10, 128)           0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 171076 (668.27 KB)\n",
      "Trainable params: 171076 (668.27 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 9.5936 - accuracy: 0.2501 - val_loss: 4.9885 - val_accuracy: 0.2619\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 2s 31ms/step - loss: 5.3370 - accuracy: 0.2449 - val_loss: 2.4103 - val_accuracy: 0.2572\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 3.8691 - accuracy: 0.2577 - val_loss: 1.8447 - val_accuracy: 0.2544\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 2.6560 - accuracy: 0.2331 - val_loss: 1.8321 - val_accuracy: 0.2435\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 3.1128 - accuracy: 0.2478 - val_loss: 2.0872 - val_accuracy: 0.2520\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 2s 36ms/step - loss: 2.8647 - accuracy: 0.2468 - val_loss: 2.1907 - val_accuracy: 0.2572\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 2s 36ms/step - loss: 3.5006 - accuracy: 0.2478 - val_loss: 2.1249 - val_accuracy: 0.2468\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 2s 36ms/step - loss: 2.7298 - accuracy: 0.2435 - val_loss: 2.3151 - val_accuracy: 0.2572\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 2s 36ms/step - loss: 2.5996 - accuracy: 0.2511 - val_loss: 2.0481 - val_accuracy: 0.2506\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 2s 37ms/step - loss: 3.1559 - accuracy: 0.2482 - val_loss: 1.9364 - val_accuracy: 0.2440\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_valid, y_train_valid, epochs=10, validation_data=(X_train_valid, y_train_valid))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
